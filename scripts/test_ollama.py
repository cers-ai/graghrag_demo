#!/usr/bin/env python3
"""
Ollamaæ¨¡å‹æµ‹è¯•è„šæœ¬
"""

import json
import time

import ollama
from loguru import logger


def test_ollama_connection():
    """æµ‹è¯•Ollamaè¿æ¥"""
    logger.info("æ­£åœ¨æµ‹è¯•Ollamaè¿æ¥...")

    try:
        # è·å–æ¨¡å‹åˆ—è¡¨
        models = ollama.list()
        logger.info(f"âœ… Ollamaè¿æ¥æˆåŠŸï¼")

        if "models" in models:
            logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹æ•°é‡: {len(models['models'])}")

            for model in models["models"]:
                name = model.get("name", "Unknown")
                size = model.get("size", 0)
                logger.info(f"  ğŸ“¦ {name} (å¤§å°: {size // (1024**3):.1f}GB)")
        else:
            logger.info(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯: {models}")

        return True

    except Exception as e:
        logger.error(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
        return False


def test_model_generation(model_name="qwen3:4b"):
    """æµ‹è¯•æ¨¡å‹ç”ŸæˆåŠŸèƒ½"""
    logger.info(f"æ­£åœ¨æµ‹è¯•æ¨¡å‹ {model_name} çš„ç”ŸæˆåŠŸèƒ½...")

    try:
        # ç®€å•çš„æµ‹è¯•æç¤º
        prompt = "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"

        logger.info(f"ğŸ“ æµ‹è¯•æç¤º: {prompt}")

        start_time = time.time()

        # è°ƒç”¨æ¨¡å‹
        response = ollama.generate(
            model=model_name,
            prompt=prompt,
            options={"temperature": 0.7, "max_tokens": 100},
        )

        end_time = time.time()
        duration = end_time - start_time

        response_text = response["response"]
        logger.info(f"ğŸ¤– æ¨¡å‹å“åº”: {response_text}")
        logger.info(f"â±ï¸ å“åº”æ—¶é—´: {duration:.2f}ç§’")

        return True

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_knowledge_extraction(model_name="qwen3:4b"):
    """æµ‹è¯•çŸ¥è¯†æŠ½å–åŠŸèƒ½"""
    logger.info(f"æ­£åœ¨æµ‹è¯•æ¨¡å‹ {model_name} çš„çŸ¥è¯†æŠ½å–åŠŸèƒ½...")

    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    å¼ ä¸‰æ˜¯ABCå…¬å¸çš„é¡¹ç›®ç»ç†ï¼Œè´Ÿè´£ç®¡ç†çŸ¥è¯†å›¾è°±é¡¹ç›®ã€‚
    æå››æ˜¯è¯¥å…¬å¸çš„å¼€å‘å·¥ç¨‹å¸ˆï¼Œå‚ä¸é¡¹ç›®å¼€å‘å·¥ä½œã€‚
    ç‹äº”æ˜¯äº§å“ç»ç†ï¼Œè´Ÿè´£éœ€æ±‚åˆ†æã€‚
    è¿™ä¸ªé¡¹ç›®å±äºæŠ€æœ¯éƒ¨é—¨ï¼Œé¢„è®¡åœ¨2024å¹´å®Œæˆã€‚
    """

    # çŸ¥è¯†æŠ½å–æç¤ºè¯
    extraction_prompt = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æŠ½å–å®ä½“å’Œå…³ç³»ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

æ–‡æœ¬ï¼š{test_text}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
{{
    "entities": [
        {{"type": "Person", "name": "å®ä½“åç§°", "properties": {{"title": "èŒä½", "department": "éƒ¨é—¨"}}}},
        {{"type": "Organization", "name": "å®ä½“åç§°", "properties": {{"type": "å…¬å¸ç±»å‹"}}}},
        {{"type": "Project", "name": "å®ä½“åç§°", "properties": {{"status": "çŠ¶æ€"}}}}
    ],
    "relations": [
        {{"source": "æºå®ä½“", "target": "ç›®æ ‡å®ä½“", "type": "å…³ç³»ç±»å‹", "properties": {{}}}}
    ]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""

    try:
        logger.info("ğŸ“ æµ‹è¯•çŸ¥è¯†æŠ½å–...")

        start_time = time.time()

        response = ollama.generate(
            model=model_name,
            prompt=extraction_prompt,
            options={"temperature": 0.1, "max_tokens": 500},  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
        )

        end_time = time.time()
        duration = end_time - start_time

        response_text = response["response"].strip()
        logger.info(f"ğŸ¤– æŠ½å–ç»“æœ: {response_text}")
        logger.info(f"â±ï¸ æŠ½å–æ—¶é—´: {duration:.2f}ç§’")

        # å°è¯•è§£æJSON
        try:
            extracted_data = json.loads(response_text)
            logger.info("âœ… JSONè§£ææˆåŠŸ")
            logger.info(f"ğŸ“Š æŠ½å–åˆ° {len(extracted_data.get('entities', []))} ä¸ªå®ä½“")
            logger.info(f"ğŸ“Š æŠ½å–åˆ° {len(extracted_data.get('relations', []))} ä¸ªå…³ç³»")
            return True
        except json.JSONDecodeError:
            logger.warning("âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½†æ¨¡å‹å“åº”æ­£å¸¸")
            return True

    except Exception as e:
        logger.error(f"âŒ çŸ¥è¯†æŠ½å–æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 50)
    logger.info("Ollamaæ¨¡å‹æµ‹è¯•")
    logger.info("=" * 50)

    # æµ‹è¯•è¿æ¥
    if not test_ollama_connection():
        return False

    logger.info("")

    # æµ‹è¯•åŸºæœ¬ç”Ÿæˆ
    if not test_model_generation():
        return False

    logger.info("")

    # æµ‹è¯•çŸ¥è¯†æŠ½å–
    if not test_knowledge_extraction():
        return False

    logger.info("")
    logger.info("âœ… æ‰€æœ‰Ollamaæµ‹è¯•é€šè¿‡ï¼")
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
